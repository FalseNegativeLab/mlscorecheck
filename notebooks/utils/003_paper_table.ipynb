{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mlscorecheck.scores import score_specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(score_specifications.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'abbreviation', 'lower_bound', 'upper_bound', 'complement',\n",
       "       'args', 'formula', 'args_standardized', 'formula_standardized',\n",
       "       'polynomial_equation', 'higher_better', 'description', 'citation',\n",
       "       'synonyms', 'nans', 'nans_standardized', 'dependency_breaks',\n",
       "       'args_short', 'formula_short', 'nans_short', 'sqrt',\n",
       "       'relationship_breaks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_width = 10\n",
    "abbr_width = 4\n",
    "form_width = 25\n",
    "short_width = 17\n",
    "descr_width = 27\n",
    "\n",
    "total = name_width + abbr_width + form_width + short_width + descr_width\n",
    "total = total * 1.05\n",
    "name_width /= total\n",
    "abbr_width /= total\n",
    "form_width /= total\n",
    "short_width /= total\n",
    "descr_width /= total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['abbreviation'].isin(['err', 'fnr', 'fpr', 'fdr', 'for_', 'f1p', 'f1n'])].reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'p': sp.Symbol('p'),\n",
    "            'n': sp.Symbol('n'),\n",
    "            'tp': sp.Symbol('tp'),\n",
    "            'tn': sp.Symbol('tn'),\n",
    "            'beta_positive': sp.Symbol('beta_+'),\n",
    "            'beta_negative': sp.Symbol('beta_-'),\n",
    "            'sqrt': sp.sqrt,\n",
    "            'f1n': sp.Symbol('f^1_-'),\n",
    "            'f1p': sp.Symbol('f^1_+'),\n",
    "            'ppv': sp.Symbol('ppv'),\n",
    "            'sens': sp.Symbol('sens'),\n",
    "            'spec': sp.Symbol('spec'),\n",
    "            'npv': sp.Symbol('npv'),\n",
    "            'mk': sp.Symbol('mk'),\n",
    "            'bm': sp.Symbol('bm'),\n",
    "            'lrp': sp.Symbol('lr_+'),\n",
    "            'lrn': sp.Symbol('lr_-')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula_to_latex(formula):\n",
    "    if formula is None or not isinstance(formula, str):\n",
    "        return ''\n",
    "    return '$' + sp.latex(eval(formula, symbols))+ '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_latex'] = df['formula_short'].apply(formula_to_latex)\n",
    "df['formula_latex'] = df['formula_standardized'].apply(formula_to_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(name):\n",
    "    if name == 'fowlkes_mallows_index':\n",
    "        return 'Fowlkes-Mallows index'\n",
    "    if name == 'jaccard_index':\n",
    "        return 'Jaccard index'\n",
    "    if name == 'cohens_kappa':\n",
    "        return \"Cohen's kappa\"\n",
    "    if name == 'f_beta_positive':\n",
    "        return '$f^{\\\\beta}_+$'\n",
    "    if name == 'f_beta_negative':\n",
    "        return '$f^{\\\\beta}_-$'\n",
    "    if name == 'matthews_correlation_coefficient':\n",
    "        return 'Matthews correlation coefficient'\n",
    "    if name == 'delta_p':\n",
    "        return '$\\Delta p$'\n",
    "    if name == 'err':\n",
    "        return 'error rate'\n",
    "    if name == 'fnr':\n",
    "        return 'false negative rate'\n",
    "    if name == 'fpr':\n",
    "        return 'false positive rate'\n",
    "    if name == 'fdr':\n",
    "        return 'false discovery rate'\n",
    "    if name == 'for_':\n",
    "        return 'false omission rate'\n",
    "    return name.replace('_', ' ')\n",
    "\n",
    "def break_name(name):\n",
    "    return ' \\\\\\\\ '.join(name.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_column(row):\n",
    "    name = '{' + row['name'] + '}' + ' \\cite{'+row[\"citation\"]+'}'\n",
    "    \n",
    "    if row['synonyms'] is None or not isinstance(row['synonyms'], list):\n",
    "        synonyms = []\n",
    "    else:\n",
    "        synonyms = row['synonyms']\n",
    "    all_names = [name] + synonyms\n",
    "    \n",
    "    all_names = [name.replace('_', ' ') for name in all_names]\n",
    "    \n",
    "    return ', '.join(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_citation(row):\n",
    "    final = break_name(rename(row['name'])) + ' \\cite{'+row[\"citation\"]+'}'\n",
    "    return '\\\\parbox{' + str(name_width) + '\\\\textwidth}{' + final + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def also_known_as(row):\n",
    "    description = row['description']\n",
    "    if row['synonyms'] is None or not isinstance(row['synonyms'], list):\n",
    "        synonyms = []\n",
    "    else:\n",
    "        synonyms = row['synonyms']\n",
    "    \n",
    "    synonyms = [rename(syn) for syn in synonyms]\n",
    "    \n",
    "    if len(synonyms) > 0:\n",
    "        synonyms = [syn.replace('_', ' ') for syn in synonyms]\n",
    "        description = description + ' Also known as: %s' % ', '.join(synonyms) + '.'\n",
    "    if isinstance(row['complement'], str):\n",
    "        complement = rename(row['complement'])\n",
    "        description = description + (' Complement: %s' % complement) + '.'\n",
    "    \n",
    "    description = description.replace('f_1', '$f_1$')\n",
    "    description = description.replace('f1_negative', '$f^1_-$')\n",
    "    description = description.replace('f1_positive', '$f^1_+$')\n",
    "    \n",
    "    description = '\\\\parbox{' + str(descr_width) + '\\\\textwidth}{' + description + '}'\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_extended'] = df.apply(name_column, axis=1)\n",
    "df['name_citation'] = df.apply(name_citation, axis=1)\n",
    "df['description_aka'] = df.apply(also_known_as, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[['name_citation', 'abbreviation', 'formula_latex', 'short_latex', 'description_aka']]\n",
    "tmp.columns = ['name', 'abbr.', 'standardized form', 'original definition', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_width = 'p{' + str(name_width) + '\\\\textwidth}@{\\hspace{2pt}}'\n",
    "abbr_width = 'p{' + str(abbr_width) + '\\\\textwidth}@{\\hspace{2pt}}'\n",
    "form_width = 'p{' + str(form_width) + '\\\\textwidth}@{\\hspace{2pt}}'\n",
    "short_width = 'p{' + str(short_width) + '\\\\textwidth}@{\\hspace{2pt}}'\n",
    "descr_width = 'p{' + str(descr_width) + '\\\\textwidth}'\n",
    "cols = name_width + abbr_width + form_width + short_width + descr_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = tmp.to_latex(index=False).replace('frac', 'dfrac').replace('lllll', cols)\n",
    "latex = latex.replace('tp tn', 'tp \\cdot tn')\n",
    "latex = latex.replace('tn tp', 'tn \\cdot tp')\n",
    "latex = latex.replace('n tp', 'n \\cdot tp')\n",
    "latex = latex.replace('n tn', 'n \\cdot tn')\n",
    "latex = latex.replace('p tn', 'p \\cdot tn')\n",
    "latex = latex.replace('p tp', 'p \\cdot tp')\n",
    "latex = latex.replace('bm mk', 'bm \\cdot mk')\n",
    "latex = latex.replace('sens spec', 'sens \\cdot spec')\n",
    "latex = latex.replace('ppv sens', 'ppv \\cdot sens')\n",
    "latex = latex.replace('sens spec', 'sens \\cdot spec')\n",
    "latex = latex.replace('f^{1}_{+} f^{1}_{-}', 'f^{1}_{+} \\cdot f^{1}_{-}')\n",
    "latex = latex.replace('\\dfrac{\\sqrt{tn} \\sqrt{tp}}{\\sqrt{n} \\sqrt{p}}', '\\sqrt{\\dfrac{tn \\cdot tp}{np}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{p{0.11474469305794606\\textwidth}@{\\hspace{2pt}}p{0.045897877223178424\\textwidth}@{\\hspace{2pt}}p{0.28686173264486514\\textwidth}@{\\hspace{2pt}}p{0.1950659781985083\\textwidth}@{\\hspace{2pt}}p{0.3098106712564544\\textwidth}}\n",
      "\\toprule\n",
      "name & abbr. & standardized form & original definition & description \\\\\n",
      "\\midrule\n",
      "\\parbox{0.11474469305794606\\textwidth}{accuracy \\cite{scores}} & acc & $\\dfrac{tn + tp}{n + p}$ &  & \\parbox{0.3098106712564544\\textwidth}{The proportion of correctly classified items. Complement: error rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{sensitivity \\cite{scores}} & sens & $\\dfrac{tp}{p}$ &  & \\parbox{0.3098106712564544\\textwidth}{The proportion of correctly classified positive items. Also known as: recall, true positive rate. Complement: false negative rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{specificity \\cite{scores}} & spec & $\\dfrac{tn}{n}$ &  & \\parbox{0.3098106712564544\\textwidth}{The proportion of correctly classified negative items. Also known as: selectivity, true negative rate. Complement: false positive rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{positive \\\\ predictive \\\\ value \\cite{scores}} & ppv & $\\dfrac{tp}{n - tn + tp}$ &  & \\parbox{0.3098106712564544\\textwidth}{The proportion of truly positive items among all items classified as positive. Also known as: precision. Complement: false discovery rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{negative \\\\ predictive \\\\ value \\cite{scores}} & npv & $\\dfrac{tn}{p + tn - tp}$ &  & \\parbox{0.3098106712564544\\textwidth}{The proportion of truly negative items among all items classified as negative. Complement: false omission rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{$f^{\\beta}_+$ \\cite{scores}} & fbp & $\\dfrac{tp \\left(\\beta_{+}^{2} + 1\\right)}{\\beta_{+}^{2} p + n - tn + tp}$ &  & \\parbox{0.3098106712564544\\textwidth}{The harmonic mean of true positive rate and sensitivity, when sensitivity is beta times more important than the true positive rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{$f^{\\beta}_-$ \\cite{upm}} & fbn & $\\dfrac{tn \\left(\\beta_{-}^{2} + 1\\right)}{\\beta_{-}^{2} n + p + tn - tp}$ &  & \\parbox{0.3098106712564544\\textwidth}{The harmonic mean of true negative rate and specificity, when specificity is beta times more important than the true negative rate.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{unified \\\\ performance \\\\ measure \\cite{upm}} & upm & $\\dfrac{4 tn \\cdot tp}{tn \\left(n + p - tn + tp\\right) + tp \\left(n + p + tn - tp\\right)}$ & $\\dfrac{2 f^{1}_{+} \\cdot f^{1}_{-}}{f^{1}_{+} + f^{1}_{-}}$ & \\parbox{0.3098106712564544\\textwidth}{The harmonic mean of $f^1_-$ and $f^1_+$.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{geometric \\\\ mean \\cite{scores}} & gm & $\\sqrt{\\dfrac{tn \\cdot tp}{np}}$ & $\\sqrt{sens \\cdot spec}$ & \\parbox{0.3098106712564544\\textwidth}{The geometric mean of sensitivity and specificity.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{Fowlkes-Mallows \\\\ index \\cite{fm}} & fm & $\\dfrac{tp}{\\sqrt{p \\left(n - tn + tp\\right)}}$ & $\\sqrt{ppv \\cdot sens}$ & \\parbox{0.3098106712564544\\textwidth}{The geometric mean of positive predictive value and sensitivity.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{markedness \\cite{mkbm}} & mk & $\\dfrac{tn}{p + tn - tp} + \\dfrac{tp}{n - tn + tp} - 1$ & $npv + ppv - 1$ & \\parbox{0.3098106712564544\\textwidth}{The markedness quantifies how marked a condition is for the predictor. Also known as: $\\Delta p$.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{bookmaker \\\\ informedness \\cite{mkbm}} & bm & $-1 + \\dfrac{tp}{p} + \\dfrac{tn}{n}$ & $sens + spec - 1$ & \\parbox{0.3098106712564544\\textwidth}{Quantifies how informed the classifier is for the specified condition. Also known as: informedness.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{Matthews \\\\ correlation \\\\ coefficient \\cite{scores}} & mcc & $\\dfrac{tn \\cdot tp - \\left(n - tn\\right) \\left(p - tp\\right)}{\\sqrt{n p \\left(n - tn + tp\\right) \\left(p + tn - tp\\right)}}$ & $\\sqrt{bm \\cdot mk}$ & \\parbox{0.3098106712564544\\textwidth}{The Pearson correlation coefficient computed for the observed and predicted labels. Also known as: phy coefficient.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{positive \\\\ likelihood \\\\ ratio \\cite{scores}} & lrp & $\\dfrac{n \\cdot tp}{p \\left(n - tn\\right)}$ & $\\dfrac{sens}{1 - spec}$ & \\parbox{0.3098106712564544\\textwidth}{Quantifies the probability of correct positive prediction relative to the probability of type I error.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{negative \\\\ likelihood \\\\ ratio \\cite{scores}} & lrn & $\\dfrac{n \\left(p - tp\\right)}{p \\cdot tn}$ & $\\dfrac{spec}{1 - sens}$ & \\parbox{0.3098106712564544\\textwidth}{Quantifies the probability of type II error relative to the probability of correct negative prediction.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{prevalence \\\\ threshold \\cite{pt}} & pt & $- \\dfrac{p \\left(n \\sqrt{\\dfrac{tp \\left(n - tn\\right)}{n p}} - n + tn\\right)}{- n \\cdot tp + p \\left(n - tn\\right)}$ & $\\dfrac{spec + \\sqrt{sens \\left(1 - spec\\right)} - 1}{sens + spec - 1}$ & \\parbox{0.3098106712564544\\textwidth}{Estimates the threshold on prevalence under which the precision of classification declines rapidly.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{diagnostic \\\\ odds \\\\ ratio \\cite{scores}} & dor & $\\dfrac{tn \\cdot tp}{\\left(n - tn\\right) \\left(p - tp\\right)}$ & $\\dfrac{lr_{+}}{lr_{-}}$ & \\parbox{0.3098106712564544\\textwidth}{The ratio of the odds that tha classifier correctly predicts a positive label to the odds of incorrectly predicting the positive label.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{Jaccard \\\\ index \\cite{scores}} & ji & $\\dfrac{tp}{n + p - tn}$ &  & \\parbox{0.3098106712564544\\textwidth}{The intersection over the union respecting items predicted positive and observed positive. Also known as: threat score, ratio of verification, critical success index, Tanimoto coefficient.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{balanced \\\\ accuracy \\cite{scores}} & bacc & $\\dfrac{tp}{2 p} + \\dfrac{tn}{2 n}$ & $\\dfrac{sens}{2} + \\dfrac{spec}{2}$ & \\parbox{0.3098106712564544\\textwidth}{The mean of sensitivity and specificity.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{Cohen's \\\\ kappa \\cite{kappa}} & kappa & $\\dfrac{- 2 n p + 2 n \\cdot tp + 2 p \\cdot tn}{n^{2} - n \\cdot tn + n \\cdot tp + p^{2} + p \\cdot tn - p \\cdot tp}$ &  & \\parbox{0.3098106712564544\\textwidth}{Quantifies the agreement between the observed labeling and the labeling by the classifier, taking into account the probability of agreement by chance.} \\\\\n",
      "\\parbox{0.11474469305794606\\textwidth}{p4 \\cite{kappa}} & p4 & $\\dfrac{4 tn \\cdot tp}{4 tn \\cdot tp + \\left(tn + tp\\right) \\left(n + p - tn - tp\\right)}$ &  & \\parbox{0.3098106712564544\\textwidth}{The harmonic mean of sensitivity, specificity, positive predictive value and negative predictive value. Similar to $f_1$, but contains all elementary figures.} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlscorecheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
