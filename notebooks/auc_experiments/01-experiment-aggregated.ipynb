{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mlscorecheck.auc import simplify_roc, average_n_roc_curves\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from config import generate_random_classifier, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 50_000\n",
    "#N_SAMPLES = 2_400\n",
    "output_file = 'raw-aggregated-50k.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function common_datasets.binary_classification._binary_classification_part0.load_abalone9_18()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_appendicitis()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_australian()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_bupa()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_cm1()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_crx()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_dermatology_6()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part0.load_ecoli1()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part0.load_glass0()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_haberman()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_hepatitis()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_hypothyroid()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_ionosphere()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_iris0()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_kc1()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_mammographic()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_monk_2()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_new_thyroid1()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_page_blocks_1_3_vs_4()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_pc1()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_pima()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_saheart()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_satimage()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_segment0()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_shuttle_c0_vs_c4()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_spectf()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_vehicle0()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_vowel0()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_wdbc()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part1.load_wisconsin()>,\n",
       " <function common_datasets.binary_classification._binary_classification_part0.load_yeast1()>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [dataset()['name'] for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_datasets.binary_classification import summary_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = summary_pdf[summary_pdf['name'].isin(names)].reset_index(drop=True)\n",
    "tmp = tmp[['name', 'n_col', 'n', 'n_minority', 'imbalance_ratio', 'citation_key']]\n",
    "tmp['name_key'] = tmp.apply(lambda row: f'{row[\"name\"]} \\\\cite{{{row[\"citation_key\"]}}}', axis=1)\n",
    "tmp = tmp[['name_key', 'n', 'n_col', 'n_minority', 'imbalance_ratio']]\n",
    "tmp.columns = ['name', 'size', 'attr.', 'p', 'imb. ratio']\n",
    "tmp['n'] = tmp['size'] - tmp['p']\n",
    "tmp = tmp[['name', 'size', 'attr.', 'p', 'n', 'imb. ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      " & name & size & attr. & p & n & imb. ratio \\\\\n",
      "\\midrule\n",
      "1 & abalone9 18 \\cite{keel} & 731 & 9 & 42 & 689 & 16.40 \\\\\n",
      "2 & appendicitis \\cite{keel} & 106 & 7 & 21 & 85 & 4.05 \\\\\n",
      "3 & australian \\cite{keel} & 690 & 16 & 307 & 383 & 1.25 \\\\\n",
      "4 & bupa \\cite{keel} & 345 & 6 & 145 & 200 & 1.38 \\\\\n",
      "5 & CM1 \\cite{krnn} & 498 & 21 & 49 & 449 & 9.16 \\\\\n",
      "6 & crx \\cite{keel} & 653 & 37 & 296 & 357 & 1.21 \\\\\n",
      "7 & dermatology-6 \\cite{keel} & 358 & 34 & 20 & 338 & 16.90 \\\\\n",
      "8 & ecoli1 \\cite{keel} & 336 & 7 & 77 & 259 & 3.36 \\\\\n",
      "9 & glass0 \\cite{keel} & 214 & 9 & 70 & 144 & 2.06 \\\\\n",
      "10 & haberman \\cite{keel} & 306 & 3 & 81 & 225 & 2.78 \\\\\n",
      "11 & hepatitis \\cite{krnn} & 155 & 19 & 32 & 123 & 3.84 \\\\\n",
      "12 & hypothyroid \\cite{krnn} & 3163 & 25 & 151 & 3012 & 19.95 \\\\\n",
      "13 & ionosphere \\cite{keel} & 351 & 33 & 126 & 225 & 1.79 \\\\\n",
      "14 & iris0 \\cite{keel} & 150 & 4 & 50 & 100 & 2.00 \\\\\n",
      "15 & KC1 \\cite{krnn} & 2109 & 21 & 326 & 1783 & 5.47 \\\\\n",
      "16 & mammographic \\cite{keel} & 830 & 5 & 403 & 427 & 1.06 \\\\\n",
      "17 & monk-2 \\cite{keel} & 432 & 6 & 204 & 228 & 1.12 \\\\\n",
      "18 & new thyroid1 \\cite{keel} & 215 & 5 & 35 & 180 & 5.14 \\\\\n",
      "19 & page-blocks-1-3 vs 4 \\cite{keel} & 472 & 10 & 28 & 444 & 15.86 \\\\\n",
      "20 & PC1 \\cite{krnn} & 1109 & 21 & 77 & 1032 & 13.40 \\\\\n",
      "21 & pima \\cite{keel} & 768 & 8 & 268 & 500 & 1.87 \\\\\n",
      "22 & saheart \\cite{keel} & 462 & 9 & 160 & 302 & 1.89 \\\\\n",
      "23 & SATIMAGE \\cite{krnn} & 6435 & 36 & 626 & 5809 & 9.28 \\\\\n",
      "24 & segment0 \\cite{keel} & 2308 & 19 & 329 & 1979 & 6.02 \\\\\n",
      "25 & shuttle-c0-vs-c4 \\cite{keel} & 1829 & 9 & 123 & 1706 & 13.87 \\\\\n",
      "26 & SPECTF \\cite{krnn} & 267 & 44 & 55 & 212 & 3.85 \\\\\n",
      "27 & vehicle0 \\cite{keel} & 846 & 18 & 199 & 647 & 3.25 \\\\\n",
      "28 & vowel0 \\cite{keel} & 988 & 13 & 90 & 898 & 9.98 \\\\\n",
      "29 & wdbc \\cite{keel} & 569 & 30 & 212 & 357 & 1.68 \\\\\n",
      "30 & wisconsin \\cite{keel} & 683 & 9 & 239 & 444 & 1.86 \\\\\n",
      "31 & yeast1 \\cite{keel} & 1484 & 8 & 429 & 1055 & 2.46 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.index = [idx for idx in range(1, len(tmp)+1)]\n",
    "print(tmp.to_latex(float_format=\"%.2f\").replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_sens_spec_at_th(y_test, y_pred, th):\n",
    "    tp = np.sum((y_pred >= th) & (y_test == 1))\n",
    "    tn = np.sum((y_pred < th) & (y_test == 0))\n",
    "    p = np.sum(y_test)\n",
    "    n = len(y_test) - np.sum(y_test)\n",
    "\n",
    "    return (tp + tn)/(p + n), tp/p, tn/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(y_test, y_pred, y_train, random_state, label=''):\n",
    "    threshold = np.sum(y_train)/len(y_train)\n",
    "\n",
    "    acc, sens, spec = acc_sens_spec_at_th(y_test, y_pred, threshold)\n",
    "\n",
    "    best_ths = []\n",
    "    best_acc = 0\n",
    "    for th in np.hstack([np.unique(y_pred), np.array([-np.inf, np.inf])]):\n",
    "        acc_tmp, _, _ = acc_sens_spec_at_th(y_test, y_pred, th)\n",
    "\n",
    "        if acc_tmp > best_acc:\n",
    "            best_acc = acc_tmp\n",
    "            best_ths = [th]\n",
    "        elif acc_tmp == best_acc:\n",
    "            best_ths.append(th)\n",
    "\n",
    "    best_th = random_state.choice(best_ths)\n",
    "\n",
    "    best_acc, best_sens, best_spec = acc_sens_spec_at_th(y_test, y_pred, best_th)\n",
    "\n",
    "    return {\n",
    "        f'acc{label}': acc,\n",
    "        f'sens{label}': sens,\n",
    "        f'spec{label}': spec,\n",
    "        f'threshold{label}': threshold,\n",
    "        f'best_acc{label}': best_acc,\n",
    "        f'best_sens{label}': best_sens,\n",
    "        f'best_spec{label}': best_spec,\n",
    "        f'best_threshold{label}': best_th\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_aggregated_scores(y_trues, y_preds, random_state, label=''):\n",
    "    thresholds = np.unique(np.hstack(y_preds))\n",
    "\n",
    "    best_ths = []\n",
    "    best_acc = 0\n",
    "    for th in thresholds.tolist() + [np.inf, -np.inf]:\n",
    "        acc_tmp = np.mean([acc_sens_spec_at_th(y_true, y_pred, th)[0] for y_true, y_pred in zip(y_trues, y_preds)])\n",
    "\n",
    "        if acc_tmp > best_acc:\n",
    "            best_acc = acc_tmp\n",
    "            best_ths = [th]\n",
    "        elif acc_tmp == best_acc:\n",
    "            best_ths.append(th)\n",
    "\n",
    "    best_th = random_state.choice(best_ths)\n",
    "\n",
    "    scores = [acc_sens_spec_at_th(y_true, y_pred, best_th) for y_true, y_pred in zip(y_trues, y_preds)]\n",
    "\n",
    "    best_acc = np.mean([item[0] for item in scores])\n",
    "    best_sens = np.mean([item[1] for item in scores])\n",
    "    best_spec = np.mean([item[2] for item in scores])\n",
    "\n",
    "    return {\n",
    "        f'best_acc{label}': best_acc,\n",
    "        f'best_sens{label}': best_sens,\n",
    "        f'best_spec{label}': best_spec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(fold_results, random_state):\n",
    "    results = {}\n",
    "\n",
    "    results = results | best_aggregated_scores(\n",
    "        [record['y_test'] for record in fold_results],\n",
    "        [record['y_pred'] for record in fold_results],\n",
    "        random_state\n",
    "    )\n",
    "\n",
    "    results = results | best_aggregated_scores(\n",
    "        [record['y_train'] for record in fold_results],\n",
    "        [record['y_pred_train'] for record in fold_results],\n",
    "        random_state,\n",
    "        label='_train'\n",
    "    )\n",
    "\n",
    "    results = results | {\n",
    "        'acc': np.mean([record['acc'] for record in fold_results]),\n",
    "        'sens': np.mean([record['sens'] for record in fold_results]),\n",
    "        'spec': np.mean([record['spec'] for record in fold_results]),\n",
    "        'auc': np.mean([record['auc'] for record in fold_results]),\n",
    "        'acc_train': np.mean([record['acc_train'] for record in fold_results]),\n",
    "        'sens_train': np.mean([record['sens_train'] for record in fold_results]),\n",
    "        'spec_train': np.mean([record['spec_train'] for record in fold_results]),\n",
    "        'auc_train': np.mean([record['auc_train'] for record in fold_results])\n",
    "    }\n",
    "\n",
    "    roc = []\n",
    "    roc_train = []\n",
    "\n",
    "    for record in fold_results:\n",
    "        fprs, tprs, thresholds = simplify_roc(*roc_curve(record['y_test'], record['y_pred']))\n",
    "        roc.append((fprs, tprs))\n",
    "        fprs_train, tprs_train, thresholds_train = simplify_roc(*roc_curve(record['y_train'], record['y_pred_train']))\n",
    "        roc_train.append((fprs_train, tprs_train))\n",
    "\n",
    "    fprs, tprs = average_n_roc_curves(roc, random_state)\n",
    "    fprs_train, tprs_train = average_n_roc_curves(roc_train, random_state)\n",
    "\n",
    "    avg_n_nodes = np.mean([len(curve[0]) for curve in roc])\n",
    "    avg_n_nodes_train = np.mean([len(curve[0]) for curve in roc_train])\n",
    "    n_nodes = len(fprs)\n",
    "    n_nodes_train = len(fprs_train)\n",
    "\n",
    "    results = results | {\n",
    "        'n_nodes': n_nodes, \n",
    "        'n_nodes_train': n_nodes_train,\n",
    "        'avg_n_nodes': avg_n_nodes,\n",
    "        'avg_n_nodes_train': avg_n_nodes_train,\n",
    "        'fprs': str(fprs.tolist()),\n",
    "        'tprs': str(tprs.tolist()),\n",
    "        'fprs_train': str(fprs_train.tolist()),\n",
    "        'tprs_train': str(tprs_train.tolist())\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            XGBClassifier                 wdbc: 100%|██████████| 50000/50000 [10:46:03<00:00,  1.29it/s]   \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "random_state = np.random.RandomState(5)\n",
    "dropped = 0\n",
    "\n",
    "with tqdm.tqdm(total=N_SAMPLES) as bar:\n",
    "    while len(results) < N_SAMPLES:\n",
    "        result = {}\n",
    "\n",
    "        loader = random_state.choice(datasets)\n",
    "        dataset = loader()\n",
    "\n",
    "        X = dataset['data']\n",
    "        y = dataset['target']\n",
    "        name = dataset['name']\n",
    "\n",
    "        if random_state.randint(2) == 0:\n",
    "            y = 1 - y\n",
    "\n",
    "        mask = np.arange(len(y))\n",
    "        random_state.shuffle(mask)\n",
    "\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "        p_total = np.sum(y)\n",
    "        n_total = len(y) - p_total\n",
    "\n",
    "        k = random_state.randint(2, 11)\n",
    "        while k > p_total or k > n_total:\n",
    "            k = random_state.randint(2, 11)\n",
    "\n",
    "        result = result | {'p': p_total, 'n': n_total, 'k': k, 'dataset': name}\n",
    "        \n",
    "        fold_results = []\n",
    "\n",
    "        classifier = generate_random_classifier(random_state, int(p_total*(1 - 1/k)), int(n_total*(1 - 1/k)))\n",
    "\n",
    "        bar.set_description(\"%25s %20s\" % (classifier[0].__name__, dataset['name']))\n",
    "        bar.refresh()\n",
    "\n",
    "        result = result | {'classifier': classifier[0].__name__, 'classifier_params': str(classifier[1])}\n",
    "\n",
    "        classifier_obj = classifier[0](**classifier[1])\n",
    "        \n",
    "        for train, test in StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state).split(X, y):\n",
    "            X_train = X[train]\n",
    "            X_test = X[test]\n",
    "            y_train = y[train]\n",
    "            y_test = y[test]\n",
    "\n",
    "            ss = StandardScaler()\n",
    "            X_train = ss.fit_transform(X_train)\n",
    "            X_test = ss.transform(X_test)\n",
    "\n",
    "            classifier_obj.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = classifier_obj.predict_proba(X_test)[:, 1]\n",
    "            y_pred_train = classifier_obj.predict_proba(X_train)[:, 1]\n",
    "\n",
    "            scores = calculate_scores(y_test, y_pred, y_train, random_state)\n",
    "            scores_train = calculate_scores(y_train, y_pred_train, y_train, random_state, '_train')\n",
    "\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "            fold_results.append(scores | scores_train | {'auc': auc, 'auc_train': auc_train, \n",
    "                    'y_pred': y_pred, 'y_test': y_test, \n",
    "                    'y_pred_train': y_pred_train, 'y_train': y_train})\n",
    "\n",
    "        if np.mean([record['auc'] for record in fold_results]) < 0.5:\n",
    "            dropped += 1\n",
    "            continue\n",
    "\n",
    "        result = result | process_results(fold_results, random_state)\n",
    "        \n",
    "        results.append(result)\n",
    "        bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>classifier_params</th>\n",
       "      <th>best_acc</th>\n",
       "      <th>best_sens</th>\n",
       "      <th>best_spec</th>\n",
       "      <th>best_acc_train</th>\n",
       "      <th>...</th>\n",
       "      <th>spec_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>n_nodes_train</th>\n",
       "      <th>avg_n_nodes</th>\n",
       "      <th>avg_n_nodes_train</th>\n",
       "      <th>fprs</th>\n",
       "      <th>tprs</th>\n",
       "      <th>fprs_train</th>\n",
       "      <th>tprs_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>bupa</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'max_depth': 76, 'random_state': 5}</td>\n",
       "      <td>0.634578</td>\n",
       "      <td>0.705753</td>\n",
       "      <td>0.537582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[0.0, 0.3891389826132473, 0.4026173392062139, ...</td>\n",
       "      <td>[0.0, 0.5909090909090909, 0.6086956521739131, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>glass0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 2, 'random_state': 5}</td>\n",
       "      <td>0.831834</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.871377</td>\n",
       "      <td>0.862110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>[0.0, 0.0, 0.01449275362318847, 0.014492753623...</td>\n",
       "      <td>[0.0, 0.3125, 0.3125, 0.5, 0.5, 0.5625, 0.5625...</td>\n",
       "      <td>[0.0, 0.0, 0.007092198581560294, 0.00709219858...</td>\n",
       "      <td>[0.0, 0.45833333333333326, 0.45833333333333326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>259</td>\n",
       "      <td>7</td>\n",
       "      <td>ecoli1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'n_neighbors': 70}</td>\n",
       "      <td>0.877976</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.949807</td>\n",
       "      <td>0.875992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848134</td>\n",
       "      <td>0.939335</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>27.571429</td>\n",
       "      <td>[0.0, 0.0, 0.0038610038610038533, 0.0193050193...</td>\n",
       "      <td>[0.0, 0.18181818181818188, 0.2727272727272727,...</td>\n",
       "      <td>[0.0, 0.0, 0.0003217503217503026, 0.0008273579...</td>\n",
       "      <td>[0.0, 0.10606060606060608, 0.13636363636363635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>ecoli1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'probability': True, 'C': 0.19005782496750956...</td>\n",
       "      <td>0.889881</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.870108</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896086</td>\n",
       "      <td>0.960603</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>[0.0, 0.0, 0.02564102564102564, 0.025641025641...</td>\n",
       "      <td>[0.0, 0.4860763267740012, 0.4860763267740012, ...</td>\n",
       "      <td>[0.0, 0.0, 0.02564102564102564, 0.025641025641...</td>\n",
       "      <td>[0.0, 0.657304710793083, 0.657304710793083, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>haberman</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'random_state': 5, 'max_depth': 4}</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904444</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>[0.0, 0.022222222222222143, 0.0222222222222221...</td>\n",
       "      <td>[0.0, 0.0, 0.03703703703703698, 0.037037037037...</td>\n",
       "      <td>[0.0, 0.0, 0.0022222222222222365, 0.0022222222...</td>\n",
       "      <td>[0.0, 0.7962962962962963, 0.7962962962962963, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     p    n  k   dataset              classifier  \\\n",
       "0  200  145  9      bupa  DecisionTreeClassifier   \n",
       "1  144   70  3    glass0  RandomForestClassifier   \n",
       "2   77  259  7    ecoli1    KNeighborsClassifier   \n",
       "3  259   77  2    ecoli1                     SVC   \n",
       "4   81  225  3  haberman           XGBClassifier   \n",
       "\n",
       "                                   classifier_params  best_acc  best_sens  \\\n",
       "0               {'max_depth': 76, 'random_state': 5}  0.634578   0.705753   \n",
       "1                {'max_depth': 2, 'random_state': 5}  0.831834   0.812500   \n",
       "2                                {'n_neighbors': 70}  0.877976   0.636364   \n",
       "3  {'probability': True, 'C': 0.19005782496750956...  0.889881   0.896064   \n",
       "4                {'random_state': 5, 'max_depth': 4}  0.735294   0.000000   \n",
       "\n",
       "   best_spec  best_acc_train  ...  spec_train  auc_train  n_nodes  \\\n",
       "0   0.537582        1.000000  ...    1.000000   1.000000       10   \n",
       "1   0.871377        0.862110  ...    0.942800   0.929068       35   \n",
       "2   0.949807        0.875992  ...    0.848134   0.939335       19   \n",
       "3   0.870108        0.910714  ...    0.896086   0.960603       53   \n",
       "4   1.000000        0.970588  ...    0.904444   0.996626       56   \n",
       "\n",
       "   n_nodes_train  avg_n_nodes  avg_n_nodes_train  \\\n",
       "0              3     3.000000           3.000000   \n",
       "1             49    21.666667          29.000000   \n",
       "2             75     9.571429          27.571429   \n",
       "3             43    28.000000          23.000000   \n",
       "4             16    39.000000          10.666667   \n",
       "\n",
       "                                                fprs  \\\n",
       "0  [0.0, 0.3891389826132473, 0.4026173392062139, ...   \n",
       "1  [0.0, 0.0, 0.01449275362318847, 0.014492753623...   \n",
       "2  [0.0, 0.0, 0.0038610038610038533, 0.0193050193...   \n",
       "3  [0.0, 0.0, 0.02564102564102564, 0.025641025641...   \n",
       "4  [0.0, 0.022222222222222143, 0.0222222222222221...   \n",
       "\n",
       "                                                tprs  \\\n",
       "0  [0.0, 0.5909090909090909, 0.6086956521739131, ...   \n",
       "1  [0.0, 0.3125, 0.3125, 0.5, 0.5, 0.5625, 0.5625...   \n",
       "2  [0.0, 0.18181818181818188, 0.2727272727272727,...   \n",
       "3  [0.0, 0.4860763267740012, 0.4860763267740012, ...   \n",
       "4  [0.0, 0.0, 0.03703703703703698, 0.037037037037...   \n",
       "\n",
       "                                          fprs_train  \\\n",
       "0                                    [0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.007092198581560294, 0.00709219858...   \n",
       "2  [0.0, 0.0, 0.0003217503217503026, 0.0008273579...   \n",
       "3  [0.0, 0.0, 0.02564102564102564, 0.025641025641...   \n",
       "4  [0.0, 0.0, 0.0022222222222222365, 0.0022222222...   \n",
       "\n",
       "                                          tprs_train  \n",
       "0                                    [0.0, 1.0, 1.0]  \n",
       "1  [0.0, 0.45833333333333326, 0.45833333333333326...  \n",
       "2  [0.0, 0.10606060606060608, 0.13636363636363635...  \n",
       "3  [0.0, 0.657304710793083, 0.657304710793083, 0....  \n",
       "4  [0.0, 0.7962962962962963, 0.7962962962962963, ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p                                                                  200\n",
       "n                                                                  145\n",
       "k                                                                    9\n",
       "dataset                                                           bupa\n",
       "classifier                                      DecisionTreeClassifier\n",
       "classifier_params                 {'max_depth': 76, 'random_state': 5}\n",
       "best_acc                                                      0.634578\n",
       "best_sens                                                     0.705753\n",
       "best_spec                                                     0.537582\n",
       "best_acc_train                                                     1.0\n",
       "best_sens_train                                                    1.0\n",
       "best_spec_train                                                    1.0\n",
       "acc                                                           0.634578\n",
       "sens                                                          0.705753\n",
       "spec                                                          0.537582\n",
       "auc                                                           0.621667\n",
       "acc_train                                                          1.0\n",
       "sens_train                                                         1.0\n",
       "spec_train                                                         1.0\n",
       "auc_train                                                          1.0\n",
       "n_nodes                                                             10\n",
       "n_nodes_train                                                        3\n",
       "avg_n_nodes                                                        3.0\n",
       "avg_n_nodes_train                                                  3.0\n",
       "fprs                 [0.0, 0.3891389826132473, 0.4026173392062139, ...\n",
       "tprs                 [0.0, 0.5909090909090909, 0.6086956521739131, ...\n",
       "fprs_train                                             [0.0, 0.0, 1.0]\n",
       "tprs_train                                             [0.0, 1.0, 1.0]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlscorecheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
