{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_datasets.binary_classification as binclas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mlscorecheck.auc import simplify_roc\n",
    "\n",
    "from common_datasets.binary_classification import summary_pdf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from config import generate_random_classifier, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 100_000\n",
    "#N_SAMPLES = 2400\n",
    "output_file = 'raw-single-100k.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [dataset()['name'] for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = summary_pdf[summary_pdf['name'].isin(names)].reset_index(drop=True)\n",
    "tmp = tmp[['name', 'n_col', 'n', 'n_minority', 'imbalance_ratio', 'citation_key']]\n",
    "tmp['name_key'] = tmp.apply(lambda row: f'{row[\"name\"]} \\\\cite{{{row[\"citation_key\"]}}}', axis=1)\n",
    "tmp = tmp[['name_key', 'n', 'n_col', 'n_minority', 'imbalance_ratio']]\n",
    "tmp.columns = ['name', 'size', 'attr.', 'p', 'imb. ratio']\n",
    "tmp['n'] = tmp['size'] - tmp['p']\n",
    "tmp = tmp[['name', 'size', 'attr.', 'p', 'n', 'imb. ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      " & name & size & attr. & p & n & imb. ratio \\\\\n",
      "\\midrule\n",
      "1 & abalone9 18 \\cite{keel} & 731 & 9 & 42 & 689 & 16.40 \\\\\n",
      "2 & appendicitis \\cite{keel} & 106 & 7 & 21 & 85 & 4.05 \\\\\n",
      "3 & australian \\cite{keel} & 690 & 16 & 307 & 383 & 1.25 \\\\\n",
      "4 & bupa \\cite{keel} & 345 & 6 & 145 & 200 & 1.38 \\\\\n",
      "5 & CM1 \\cite{krnn} & 498 & 21 & 49 & 449 & 9.16 \\\\\n",
      "6 & crx \\cite{keel} & 653 & 37 & 296 & 357 & 1.21 \\\\\n",
      "7 & dermatology-6 \\cite{keel} & 358 & 34 & 20 & 338 & 16.90 \\\\\n",
      "8 & ecoli1 \\cite{keel} & 336 & 7 & 77 & 259 & 3.36 \\\\\n",
      "9 & glass0 \\cite{keel} & 214 & 9 & 70 & 144 & 2.06 \\\\\n",
      "10 & haberman \\cite{keel} & 306 & 3 & 81 & 225 & 2.78 \\\\\n",
      "11 & hepatitis \\cite{krnn} & 155 & 19 & 32 & 123 & 3.84 \\\\\n",
      "12 & hypothyroid \\cite{krnn} & 3163 & 25 & 151 & 3012 & 19.95 \\\\\n",
      "13 & ionosphere \\cite{keel} & 351 & 33 & 126 & 225 & 1.79 \\\\\n",
      "14 & iris0 \\cite{keel} & 150 & 4 & 50 & 100 & 2.00 \\\\\n",
      "15 & KC1 \\cite{krnn} & 2109 & 21 & 326 & 1783 & 5.47 \\\\\n",
      "16 & mammographic \\cite{keel} & 830 & 5 & 403 & 427 & 1.06 \\\\\n",
      "17 & monk-2 \\cite{keel} & 432 & 6 & 204 & 228 & 1.12 \\\\\n",
      "18 & new thyroid1 \\cite{keel} & 215 & 5 & 35 & 180 & 5.14 \\\\\n",
      "19 & page-blocks-1-3 vs 4 \\cite{keel} & 472 & 10 & 28 & 444 & 15.86 \\\\\n",
      "20 & PC1 \\cite{krnn} & 1109 & 21 & 77 & 1032 & 13.40 \\\\\n",
      "21 & pima \\cite{keel} & 768 & 8 & 268 & 500 & 1.87 \\\\\n",
      "22 & saheart \\cite{keel} & 462 & 9 & 160 & 302 & 1.89 \\\\\n",
      "23 & SATIMAGE \\cite{krnn} & 6435 & 36 & 626 & 5809 & 9.28 \\\\\n",
      "24 & segment0 \\cite{keel} & 2308 & 19 & 329 & 1979 & 6.02 \\\\\n",
      "25 & shuttle-c0-vs-c4 \\cite{keel} & 1829 & 9 & 123 & 1706 & 13.87 \\\\\n",
      "26 & SPECTF \\cite{krnn} & 267 & 44 & 55 & 212 & 3.85 \\\\\n",
      "27 & vehicle0 \\cite{keel} & 846 & 18 & 199 & 647 & 3.25 \\\\\n",
      "28 & vowel0 \\cite{keel} & 988 & 13 & 90 & 898 & 9.98 \\\\\n",
      "29 & wdbc \\cite{keel} & 569 & 30 & 212 & 357 & 1.68 \\\\\n",
      "30 & wisconsin \\cite{keel} & 683 & 9 & 239 & 444 & 1.86 \\\\\n",
      "31 & yeast1 \\cite{keel} & 1484 & 8 & 429 & 1055 & 2.46 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.index = [idx for idx in range(1, len(tmp)+1)]\n",
    "print(tmp.to_latex(float_format=\"%.2f\").replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_sens_spec_at_th(y_test, y_pred, th):\n",
    "    tp = np.sum((y_pred >= th) & (y_test == 1))\n",
    "    tn = np.sum((y_pred < th) & (y_test == 0))\n",
    "    p = np.sum(y_test)\n",
    "    n = len(y_test) - np.sum(y_test)\n",
    "\n",
    "    return (tp + tn)/(p + n), tp/p, tn/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(y_test, y_pred, y_train, random_state, label=''):\n",
    "    threshold = np.sum(y_train)/len(y_train)\n",
    "\n",
    "    acc, sens, spec = acc_sens_spec_at_th(y_test, y_pred, threshold)\n",
    "\n",
    "    best_ths = []\n",
    "    best_acc = 0\n",
    "    for th in np.hstack([np.unique(y_pred), np.array([-np.inf, np.inf])]):\n",
    "        acc_tmp, _, _ = acc_sens_spec_at_th(y_test, y_pred, th)\n",
    "\n",
    "        if acc_tmp > best_acc:\n",
    "            best_acc = acc_tmp\n",
    "            best_ths = [th]\n",
    "        elif acc_tmp == best_acc:\n",
    "            best_ths.append(th)\n",
    "\n",
    "    best_th = random_state.choice(best_ths)\n",
    "\n",
    "    best_acc, best_sens, best_spec = acc_sens_spec_at_th(y_test, y_pred, best_th)\n",
    "\n",
    "    return {\n",
    "        f'acc{label}': acc,\n",
    "        f'sens{label}': sens,\n",
    "        f'spec{label}': spec,\n",
    "        f'best_acc{label}': best_acc,\n",
    "        f'best_sens{label}': best_sens,\n",
    "        f'best_spec{label}': best_spec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "def synthetic_dataset(random_state):\n",
    "    n_features = random_state.randint(2, 20)\n",
    "    n_informative = random_state.randint(1, n_features+1)\n",
    "    if n_informative < n_features:\n",
    "        n_redundant = random_state.randint(1, n_features - n_informative + 1)\n",
    "    else:\n",
    "        n_redundant = 0\n",
    "\n",
    "    n_clusters_per_class = random_state.randint(1, 2**(n_informative)/2 + 1)\n",
    "    weights = random_state.random_sample() * 0.8 + 0.1\n",
    "\n",
    "    X, y = sklearn.datasets.make_classification(\n",
    "        n_samples=random_state.randint(100, 2000), \n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative, \n",
    "        n_redundant=n_redundant, \n",
    "        n_repeated=0, \n",
    "        n_classes=2, \n",
    "        n_clusters_per_class=n_clusters_per_class, \n",
    "        weights=(weights, 1 - weights), \n",
    "        flip_y=0.01, \n",
    "        class_sep=1.0, \n",
    "        hypercube=True, \n",
    "        shift=0.0, \n",
    "        scale=1.0, \n",
    "        shuffle=True, \n",
    "        random_state=random_state\n",
    "        )\n",
    "    \n",
    "    return {'data': X, 'target': y, 'name': 'synthetic'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     KNeighborsClassifier               SPECTF: 100%|██████████| 100000/100000 [3:58:47<00:00,  6.98it/s]  \n"
     ]
    }
   ],
   "source": [
    "random_state = np.random.RandomState(5)\n",
    "dropped = 0\n",
    "results = []\n",
    "\n",
    "with tqdm.tqdm(total=N_SAMPLES) as bar:\n",
    "    while len(results) < N_SAMPLES:\n",
    "        record = {}\n",
    "\n",
    "        loader = random_state.choice(datasets)\n",
    "        dataset = loader()\n",
    "        #dataset = synthetic_dataset(random_state)\n",
    "\n",
    "        X = dataset['data']\n",
    "        y = dataset['target']\n",
    "        name = dataset['name']\n",
    "\n",
    "        record['dataset'] = name\n",
    "\n",
    "        if random_state.randint(2) == 0:\n",
    "            y = 1 - y\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X_train = ss.fit_transform(X_train)\n",
    "        X_test = ss.transform(X_test)\n",
    "\n",
    "        classifier = generate_random_classifier(random_state, p=np.sum(y_train), n=np.sum(1 - y_train))\n",
    "\n",
    "        bar.set_description(\"%25s %20s\" % (classifier[0].__name__, dataset['name']))\n",
    "        bar.refresh()\n",
    "\n",
    "        record['classifier'] = classifier[0].__name__\n",
    "        record['classifier_params'] = str(classifier[1])\n",
    "\n",
    "        classifier_obj = classifier[0](**classifier[1])\n",
    "\n",
    "        classifier_obj.fit(X_train, y_train)\n",
    "\n",
    "        if classifier[0].__name__ == 'SVC' and classifier_obj.fit_status_ == 1:\n",
    "            print('failed SVC')\n",
    "            continue\n",
    "\n",
    "        record = record | {\n",
    "            'p': np.sum(y_test), \n",
    "            'n': len(y_test) - np.sum(y_test), \n",
    "            'p_train': np.sum(y_train), \n",
    "            'n_train': len(y_train) - np.sum(y_train)\n",
    "        }\n",
    "\n",
    "        y_pred = classifier_obj.predict_proba(X_test)[:, 1]\n",
    "        y_pred_train = classifier_obj.predict_proba(X_train)[:, 1]\n",
    "\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "        record = record | {'auc': auc, 'auc_train': auc_train}\n",
    "\n",
    "        fpr, tpr, thresholds = simplify_roc(*roc_curve(y_test, y_pred))\n",
    "        fpr_train, tpr_train, thresholds_train = simplify_roc(*roc_curve(y_train, y_pred_train))\n",
    "\n",
    "        record = record | {\n",
    "            'fprs': str(fpr.tolist()), \n",
    "            'tprs': str(tpr.tolist()),\n",
    "            'thresholds': str(thresholds.tolist()),\n",
    "            'n_nodes': len(fpr),\n",
    "            'fprs_train': str(fpr_train.tolist()), \n",
    "            'tprs_train': str(tpr_train.tolist()),\n",
    "            'thresholds_train': str(thresholds_train.tolist()),\n",
    "            'n_nodes_train': len(fpr_train)\n",
    "            }\n",
    "\n",
    "        if auc < 0.5:\n",
    "            dropped += 1\n",
    "            continue\n",
    "\n",
    "        record = record | calculate_scores(y_test, y_pred, y_train, random_state)\n",
    "        record = record | calculate_scores(y_train, y_pred_train, y_train, random_state, '_train')\n",
    "\n",
    "        results.append(record)\n",
    "        bar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset                                                       haberman\n",
       "classifier                                               XGBClassifier\n",
       "classifier_params                  {'random_state': 5, 'max_depth': 4}\n",
       "p                                                                   16\n",
       "n                                                                   46\n",
       "p_train                                                             65\n",
       "n_train                                                            179\n",
       "auc                                                           0.567935\n",
       "auc_train                                                     0.994628\n",
       "fprs                 [0.0, 0.0, 0.06521739130434782, 0.065217391304...\n",
       "tprs                 [0.0, 0.125, 0.125, 0.1875, 0.1875, 0.25, 0.25...\n",
       "thresholds           [inf, 0.9796343445777893, 0.8320866823196411, ...\n",
       "n_nodes                                                             23\n",
       "fprs_train           [0.0, 0.0, 0.00558659217877095, 0.005586592178...\n",
       "tprs_train           [0.0, 0.8461538461538461, 0.8461538461538461, ...\n",
       "thresholds_train     [inf, 0.5733515024185181, 0.5676876306533813, ...\n",
       "n_nodes_train                                                       18\n",
       "acc                                                           0.548387\n",
       "sens                                                              0.25\n",
       "spec                                                          0.652174\n",
       "best_acc                                                      0.774194\n",
       "best_sens                                                        0.125\n",
       "best_spec                                                          1.0\n",
       "acc_train                                                     0.942623\n",
       "sens_train                                                         1.0\n",
       "spec_train                                                    0.921788\n",
       "best_acc_train                                                0.959016\n",
       "best_sens_train                                               0.846154\n",
       "best_spec_train                                                    1.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>classifier_params</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>p_train</th>\n",
       "      <th>n_train</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>fprs</th>\n",
       "      <th>...</th>\n",
       "      <th>spec</th>\n",
       "      <th>best_acc</th>\n",
       "      <th>best_sens</th>\n",
       "      <th>best_spec</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>sens_train</th>\n",
       "      <th>spec_train</th>\n",
       "      <th>best_acc_train</th>\n",
       "      <th>best_sens_train</th>\n",
       "      <th>best_spec_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bupa</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 55, 'random_state': 5}</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>160</td>\n",
       "      <td>116</td>\n",
       "      <td>0.781466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 0.06896551724137931, 0.068965517241...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haberman</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'random_state': 5, 'max_depth': 4}</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>179</td>\n",
       "      <td>0.567935</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>[0.0, 0.0, 0.06521739130434782, 0.065217391304...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921788</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appendicitis</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'random_state': 5, 'max_depth': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 0.05555555555555555, 0.055555555555...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 136, 'random_state': 5}</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>285</td>\n",
       "      <td>170</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 0.023809523809523808, 0.02380952380...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saheart</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 1, 'random_state': 5}</td>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>0.713371</td>\n",
       "      <td>0.789127</td>\n",
       "      <td>[0.0, 0.03125, 0.03125, 0.0625, 0.0625, 0.0937...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.692946</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset              classifier  \\\n",
       "0          bupa  RandomForestClassifier   \n",
       "1      haberman           XGBClassifier   \n",
       "2  appendicitis           XGBClassifier   \n",
       "3          wdbc  RandomForestClassifier   \n",
       "4       saheart  RandomForestClassifier   \n",
       "\n",
       "                       classifier_params   p   n  p_train  n_train       auc  \\\n",
       "0   {'max_depth': 55, 'random_state': 5}  40  29      160      116  0.781466   \n",
       "1    {'random_state': 5, 'max_depth': 4}  16  46       65      179  0.567935   \n",
       "2    {'random_state': 5, 'max_depth': 2}   4  18       17       67  0.833333   \n",
       "3  {'max_depth': 136, 'random_state': 5}  72  42      285      170  0.996032   \n",
       "4    {'max_depth': 1, 'random_state': 5}  61  32      241      128  0.713371   \n",
       "\n",
       "   auc_train                                               fprs  ...  \\\n",
       "0   1.000000  [0.0, 0.0, 0.06896551724137931, 0.068965517241...  ...   \n",
       "1   0.994628  [0.0, 0.0, 0.06521739130434782, 0.065217391304...  ...   \n",
       "2   1.000000  [0.0, 0.0, 0.05555555555555555, 0.055555555555...  ...   \n",
       "3   1.000000  [0.0, 0.0, 0.023809523809523808, 0.02380952380...  ...   \n",
       "4   0.789127  [0.0, 0.03125, 0.03125, 0.0625, 0.0625, 0.0937...  ...   \n",
       "\n",
       "       spec  best_acc  best_sens best_spec acc_train sens_train  spec_train  \\\n",
       "0  0.620690  0.768116   0.950000  0.517241  1.000000   1.000000    1.000000   \n",
       "1  0.652174  0.774194   0.125000  1.000000  0.942623   1.000000    0.921788   \n",
       "2  0.833333  0.909091   0.750000  0.944444  0.976190   1.000000    0.970149   \n",
       "3  0.976190  0.973684   0.972222  0.976190  1.000000   1.000000    1.000000   \n",
       "4  0.656250  0.698925   0.852459  0.406250  0.699187   0.692946    0.710938   \n",
       "\n",
       "   best_acc_train  best_sens_train  best_spec_train  \n",
       "0        1.000000         1.000000         1.000000  \n",
       "1        0.959016         0.846154         1.000000  \n",
       "2        1.000000         1.000000         1.000000  \n",
       "3        1.000000         1.000000         1.000000  \n",
       "4        0.756098         0.863071         0.554688  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlscorecheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
